{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Graph Structured Data on Manifolds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Learning Graph Structured Data (GSD) embeddings on manifolds received considerable attention recently. Many works showed the benefits\n",
    "of embedding GSD in hyperbolic space. In this trend, this tutorial shows how to learn embedding in the Poincaré Ball in `geomstats`. The method is applied\n",
    "to a practical and known GSD dataset, the Karate club. The latter and several other datasets are found in the `datasets.data` module.\n",
    "\n",
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the logging module, to provide practical information throughout the embedding learning process.\n",
    "`matplotlib` and the `visualization` module will allow us to draw the embedding of the GSD on the manifold. The backend is imported\n",
    "and the `PoincareBall` manifold from the `geometry` module. A specific class for managing graph data is imported as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a8b9e65943e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeomstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeomstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeomstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mvisualization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\geomstats_Hadi\\geomstats\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeomstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvariant_metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeomstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeomstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlie_algebra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeomstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlie_group\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeomstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\geomstats_Hadi\\geomstats\\geometry\\lie_algebra.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeomstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeomstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_bch_coefficients\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBCH_COEFFICIENTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\geomstats_Hadi\\geomstats\\geometry\\_bch_coefficients.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m BCH_COEFFICIENTS = gs.array([\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'geomstats.backend' has no attribute 'array'"
     ],
     "ename": "AttributeError",
     "evalue": "module 'geomstats.backend' has no attribute 'array'",
     "output_type": "error"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geomstats.backend as gs\n",
    "import geomstats.datasets.utils\n",
    "import geomstats.visualization as visualization\n",
    "from geomstats.datasets import graph_data_preparation as gdp\n",
    "from geomstats.geometry.poincare_ball import PoincareBall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Karate club is the well-known and much-used Zachary karate club network.\n",
    " The data was collected from the members of a university karate club by Wayne Zachary in 1977. \n",
    " Each node represents a member of the club, and each edge represents a tie between two members \n",
    " of the club. The graph is undirected. An often discussed problem using this dataset is to find the\n",
    "  two groups of people into which the karate club split after an argument between two teachers.\n",
    "Two variables are set as the path to the karate dataset (the graph adjacency matrix) and a second to the true \n",
    "labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "GRAPH_MATRIX_PATH = geomstats.datasets.utils.KARATE_PATH\n",
    "LABELS_PATH = geomstats.datasets.utils.KARATE_LABELS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters and Initialisation\n",
    "\n",
    "First of all, we define the main function and start by setting the following parameters needed for embedding:\n",
    "\n",
    "| Parameter | Description   |\n",
    "|------|------|\n",
    "|   random.seed  | An initial manually set number for generating pseudorandom numbers|\n",
    "| dim | Dimensions of the manifold used for embedding |\n",
    "|max_epochs|Number of iterations for learning embedding |\n",
    "|lr| Learning rate|\n",
    "|n_negative| Number of negative samples|\n",
    "|context_size| Size of the considered context for each node of the graph|\n",
    "\n",
    "Let us discuss a few things about the parameters of the above table.\n",
    "The number of dimensions should be high (i.e., 10+) for large datasets \n",
    "(i.e., where the number of nodes/edges is significantly large). \n",
    "In this tutorial we consider a dataset that is quite small with only 34 nodes. Therefore the Poincaré disk of only two dimensions is sufficient to\n",
    "capture the complexity of the graph and provide a faithful representation.\n",
    "Some parameters are hard to know in advance, such as `max_epochs` and `lr`, these should be tuned specifically per dataset.\n",
    "Visualizing can help with tuning the parameters or overmore, one can perform a grid search, to find values of these parameters \n",
    "maximising some performance. In learning embeddings, one can consider performance metrics such as\n",
    "a measure for clusters seperability or normalized mutual \n",
    "information (NMI) and so on.\n",
    "Similarly, the number of negative samples and context size can also be thought of as hyperparameters and will\n",
    "be further discussed in the sequel. An instance of the `Graph` class is created\n",
    " and set to the Karate club dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    gs.random.seed(1234)\n",
    "    dim = 2\n",
    "    max_epochs = 100\n",
    "    lr = .05\n",
    "    n_negative = 2\n",
    "    context_size = 1\n",
    "    karate_graph = gdp.Graph(\n",
    "        graph_matrix_path=GRAPH_MATRIX_PATH,\n",
    "        labels_path=LABELS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some information on the dataset are displayed to provide insight on the dataset complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    nb_vertices_by_edges =\\\n",
    "        [len(e_2) for _, e_2 in karate_graph.edges.items()]\n",
    "    logging.info('Number of edges: %s', len(karate_graph.edges))\n",
    "    logging.info(\n",
    "        'Mean vertices by edges: %s',\n",
    "        (sum(nb_vertices_by_edges, 0) / len(karate_graph.edges)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denote $V$ as the set of nodes and $E \\subset V\\times V$ the set \n",
    "of edges. The goal of embedding GSD is to provide a faithful and exploitable representation \n",
    "of the graph structure. It is mainly achieved by preserving  *first-order* proximity \n",
    "that enforces nodes sharing edges to be close to each other. It can additionally \n",
    "preserve *second-order* proximity that enforces two nodes sharing the same context \n",
    "(i.e., nodes that are neighbours but not necessarily directly connected) to be close.\n",
    "Let $\\mathbb{B}^m$ be the Poincaré Ball of dimensions $m$ equipped with the distance function $d$.\n",
    "*first* and *second-order* proximities can be achieved by optimising the following loss functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### First-order proximity.\n",
    "To preserve first-order proximity we adopt a loss function similar to <cite data-cite=\"7875465/KRA9K53S\"></cite>:\n",
    "$$ O_1 = -\\sum \\limits_{(v_i, v_j) \\in E} log(\\sigma(-d^2(\\phi_i, \\phi_j)))$$\n",
    "\n",
    "with $\\sigma(x)=\\frac{1}{1+e^{-x}}$ is the sigmoid function and $\\phi_i \\in \\mathbb{B}^m$ is the embedding of the $i$-th node of $V$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Second-order proximity.\n",
    "In order to preserve second-order proximity,\n",
    "the representation of a node has to be close to the representations of its context nodes.  For this, we adopt the negative sampling approach \\cite{NIPS2013_5021} and consider the loss:\n",
    "$$     O_2 = - \\sum\\limits_{v_i\\in V} \\sum\\limits_{v_j \\in C_i} \\bigg[ log(\\sigma(-d^2(\\phi_i, \\phi_j'))) + \\sum \\limits_{v_k\\sim \\mathcal{P}_n} log(\\sigma(d^2(\\phi_i, \\phi_k')))  \\bigg]$$\n",
    "\n",
    "\n",
    "\n",
    "with $C_i$ the nodes in the context of the $i$-th node, $\\phi_j'\\in \\mathbb{B}^m$ the embedding of $v_j\\in C_i$ and $\\mathcal{P}_n$ the negative sampling distribution over $V$: $\\mathcal{P}_n(v)=\\frac{deg(v)^{3/4}}{\\sum\\limits_{v_i\\in V}deg(v_i)^{3/4}}$. Following the \\textit{ComE} approach, we introduce in the next paragraph a third objective function in order to improve the mechanism of community detection and embedding. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    negative_table_parameter = 5\n",
    "    negative_sampling_table = []\n",
    "\n",
    "    for i, nb_v in enumerate(nb_vertices_by_edges):\n",
    "        negative_sampling_table +=\\\n",
    "            ([i] * int((nb_v**(3. / 4.))) * negative_table_parameter)\n",
    "\n",
    "    negative_sampling_table = gs.array(negative_sampling_table)\n",
    "    random_walks = karate_graph.random_walk()\n",
    "    embeddings = gs.random.normal(size=(karate_graph.n_nodes, dim))\n",
    "    embeddings = embeddings * 0.2\n",
    "\n",
    "    hyperbolic_manifold = PoincareBall(2)\n",
    "\n",
    "    colors = {1: 'b', 2: 'r'}\n",
    "    for epoch in range(max_epochs):\n",
    "        total_loss = []\n",
    "        for path in random_walks:\n",
    "\n",
    "            for example_index, one_path in enumerate(path):\n",
    "                context_index = path[max(0, example_index - context_size):\n",
    "                                     min(example_index + context_size,\n",
    "                                     len(path))]\n",
    "                negative_index =\\\n",
    "                    gs.random.randint(negative_sampling_table.shape[0],\n",
    "                                      size=(len(context_index),\n",
    "                                      n_negative))\n",
    "                negative_index = negative_sampling_table[negative_index]\n",
    "\n",
    "                example_embedding = embeddings[one_path]\n",
    "\n",
    "                for one_context_i, one_negative_i in zip(context_index,\n",
    "                                                         negative_index):\n",
    "                    context_embedding = embeddings[one_context_i]\n",
    "                    negative_embedding = embeddings[one_negative_i]\n",
    "                    l, g_ex = loss(\n",
    "                        example_embedding,\n",
    "                        context_embedding,\n",
    "                        negative_embedding,\n",
    "                        hyperbolic_manifold)\n",
    "                    total_loss.append(l)\n",
    "\n",
    "                    example_to_update = embeddings[one_path]\n",
    "                    embeddings[one_path] = hyperbolic_manifold.metric.exp(\n",
    "                        -lr * g_ex, example_to_update)\n",
    "\n",
    "        logging.info(\n",
    "            'iteration %d loss_value %f',\n",
    "            epoch, sum(total_loss, 0) / len(total_loss))\n",
    "\n",
    "    circle = visualization.PoincareDisk(point_type='ball')\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    circle.add_points(gs.array([[0, 0]]))\n",
    "    circle.set_ax(ax)\n",
    "    circle.draw(ax=ax)\n",
    "    for i_embedding, embedding in enumerate(embeddings):\n",
    "        plt.scatter(\n",
    "            embedding[0], embedding[1],\n",
    "            c=colors[karate_graph.labels[i_embedding][0]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def log_sigmoid(vector):\n",
    "    \"\"\"Logsigmoid function.\n",
    "\n",
    "    Apply log sigmoid function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vector : array-like, shape=[n_samples, dim]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : array-like, shape=[n_samples, dim]\n",
    "    \"\"\"\n",
    "    return gs.log((1 / (1 + gs.exp(-vector))))\n",
    "\n",
    "\n",
    "def grad_log_sigmoid(vector):\n",
    "    \"\"\"Gradient of log sigmoid function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vector : array-like, shape=[n_samples, dim]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gradient : array-like, shape=[n_samples, dim]\n",
    "    \"\"\"\n",
    "    return 1 / (1 + gs.exp(vector))\n",
    "\n",
    "\n",
    "def grad_squared_distance(point_a, point_b):\n",
    "    \"\"\"Gradient of squared hyperbolic distance.\n",
    "\n",
    "    Gradient of the squared distance based on the\n",
    "    Ball representation according to point_a\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    point_a : array-like, shape=[n_samples, dim]\n",
    "        First point in hyperbolic space.\n",
    "    point_b : array-like, shape=[n_samples, dim]\n",
    "        Second point in hyperbolic space.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dist : array-like, shape=[n_samples, 1]\n",
    "        Geodesic squared distance between the two points.\n",
    "    \"\"\"\n",
    "    hyperbolic_metric = PoincareBall(2).metric\n",
    "    log_map = hyperbolic_metric.log(point_b, point_a)\n",
    "\n",
    "    return -2 * log_map\n",
    "\n",
    "\n",
    "def loss(example_embedding, context_embedding, negative_embedding,\n",
    "         manifold):\n",
    "    \"\"\"Compute loss and grad.\n",
    "\n",
    "    Compute loss and grad given embedding of the current example,\n",
    "    embedding of the context and negative sampling embedding.\n",
    "    \"\"\"\n",
    "    n_edges, dim =\\\n",
    "        negative_embedding.shape[0], example_embedding.shape[-1]\n",
    "    example_embedding = gs.expand_dims(example_embedding, 0)\n",
    "    context_embedding = gs.expand_dims(context_embedding, 0)\n",
    "\n",
    "    positive_distance =\\\n",
    "        manifold.metric.squared_dist(\n",
    "            example_embedding, context_embedding)\n",
    "    positive_loss =\\\n",
    "        log_sigmoid(-positive_distance)\n",
    "\n",
    "    reshaped_example_embedding =\\\n",
    "        gs.repeat(example_embedding, n_edges, axis=0)\n",
    "\n",
    "    negative_distance =\\\n",
    "        manifold.metric.squared_dist(\n",
    "            reshaped_example_embedding, negative_embedding)\n",
    "    negative_loss = log_sigmoid(negative_distance)\n",
    "\n",
    "    total_loss = -(positive_loss + negative_loss.sum())\n",
    "\n",
    "    positive_log_sigmoid_grad =\\\n",
    "        -grad_log_sigmoid(-positive_distance)\n",
    "\n",
    "    positive_distance_grad =\\\n",
    "        grad_squared_distance(example_embedding, context_embedding)\n",
    "\n",
    "    positive_grad =\\\n",
    "        gs.repeat(positive_log_sigmoid_grad, dim, axis=-1)\\\n",
    "        * positive_distance_grad\n",
    "\n",
    "    negative_distance_grad =\\\n",
    "        grad_squared_distance(reshaped_example_embedding, negative_embedding)\n",
    "\n",
    "    negative_distance = gs.to_ndarray(negative_distance,\n",
    "                                      to_ndim=2, axis=-1)\n",
    "    negative_log_sigmoid_grad =\\\n",
    "        grad_log_sigmoid(negative_distance)\n",
    "\n",
    "    negative_grad = negative_log_sigmoid_grad\\\n",
    "        * negative_distance_grad\n",
    "\n",
    "    example_grad = -(positive_grad + negative_grad.sum(axis=0))\n",
    "\n",
    "    return total_loss, example_grad\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"cite2c-biblio\"></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "7875465/KRA9K53S": {
     "author": [
      {
       "family": "Nickel",
       "given": "Maximillian"
      },
      {
       "family": "Kiela",
       "given": "Douwe"
      }
     ],
     "container-title": "Advances in Neural Information Processing Systems 30 (NIPS)",
     "id": "7875465/KRA9K53S",
     "issued": {
      "year": 2017
     },
     "page": "6338–6347",
     "page-first": "6338",
     "publisher": "Curran Associates, Inc.",
     "title": "Poincaré Embeddings for Learning Hierarchical Representations",
     "type": "chapter"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}